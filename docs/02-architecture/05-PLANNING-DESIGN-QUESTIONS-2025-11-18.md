# 规划阶段细化设计问卷

**时间**：2025-11-18  
**基于**：新的"两轮讨论→小会澄清→第三轮→草案/规划案"模型  
**目标**：识别所有需要进一步细化的设计点

---

## 一、讨论轮次与小会流程

### 1.1 两轮讨论的"固定"策略

**问题**：
- 两轮后一定启动小会，是否意味着"有些需求天然信息充足，第一轮就能共识"的情况也要被迫进行第二轮和小会？
- 还是说：如果 Round 1 所有角色都同意，就直接跳到"生成规划案"，**跳过** Round 2 和小会？

**当前代码现状**：
- `planningMeetingAgent.mjs` 硬编码"如果有 summary，就进 Round 2"
- 无"所有角色都同意"的快速路径

**设计选项**：
```
选项 A（激进）：完全固定两轮 + 小会
  Round 1 → Round 2 → 检查共识 → 无论如何启动小会 → Round 3 → 草案/规划案

选项 B（务实）：有快速路径
  Round 1 → 检查所有角色是否同意
    ├─ 全同意 → 直接生成规划案（无 Round 2/3）
    └─ 未全同意 → Round 2 → 检查共识 → 启动小会 → Round 3 → 草案/规划案

选项 C（混合）：保留"充分性启发"
  Round 1 → Coach 给出"信息充分度评分"（0-100%）
    ├─ ≥90% 且所有角色同意 → 生成规划案
    ├─ <90% 或部分异议 → Round 2
    └─ Round 2 后无论如何启动小会
```

**我的问题**：你倾向哪个选项？还是有第四种思路？

---

### 1.2 小会中的"三角色"明确性

**问题**：
- "提出澄清问题的 AI"：是只有**一个** AI 提问，还是**多个** AI 都可能提问？
- 如果有多个 AI 提问，小会的流程是串联还是并联？

**场景举例**：
```
Round 2 结束时：
  - ProductPlanner 的 blocking_question："这个新系统要替换现有系统吗？"
  - TestPlanner 的 blocking_question："数据迁移是否在 scope 内？"

小会启动后：
  方案 a）串联：用户先回答 ProductPlanner 的问题 → 再回答 TestPlanner 的问题
  方案 b）并联：用户看到多个问题一次性回答
  方案 c）优先级：Coach 判断哪个问题更关键，先问那个
```

**当前代码现状**：
- `plan.mjs` 的 `runClarificationMiniMeeting()` 按顺序遍历 `blockingQuestions`
- 实际上是**串联**，但用户可以逐个回答或连续对话

**我的问题**：
- 用户体验上，串联还是并联更好？还是应该让 Coach（或用户）选择？
- 每个问题后是否应该有"确认"或"继续"的提示？

---

### 1.3 小会中的"信息刷新"

**问题**：
- 用户在小会中回答了澄清问题后，**已经发言过的角色**（例如 ProductPlanner）是否需要"看到新信息后重新审视"？

**设计选项**：
```
选项 A：不重新发言（当前设计暗示）
  Round 2 的各角色已发言
    ↓
  小会：用户回答澄清问题
    ↓
  Round 3：只有未充分了解情况的角色重新发言？还是全员都要？

选项 B：Round 3 全员重新发言
  Round 2 的各角色已发言
    ↓
  小会：用户回答澄清问题
    ↓
  Round 3：所有 5 个角色都基于"Round 2 共识 + 新澄清"重新给结论

选项 C：分层重新发言
  Round 2 的各角色已发言
    ↓
  小会：用户回答澄清问题
    ↓
  Round 3：只有"受澄清内容影响"的角色重新发言
    （例如：澄清内容是关于"数据量"，则 SystemDesigner 和 TestPlanner 需要重新审视）
```

**我的问题**：哪个选项最合理？还是要根据澄清内容的"影响范围"动态决定？

---

## 二、草案与规划案的分野

### 2.1 "共识"的量化标准

**问题**：
- "所有角色都同意"的定义是什么？
  - 所有角色 `ok === true`？
  - 还是"没有阻塞"（无 `ok === false`）即可？
  - 或者"≥80% 的角色同意"？

**当前代码现状**：
- `planningMeetingCore.mjs` 的决策逻辑：
  - `blocking.length > 0` → `decision = "redo_planning"`（不能生成产物）
  - `testNotOk || riskHighNotOk` → `decision = "hold"`（需要修改）
  - `planReview.ok === true` → `decision = "go"`（可以进 codegen）

**我的问题**：
- "共识"的门槛应该是什么？（所有同意 vs 多数同意 vs 无阻塞）
- 如果是"多数同意"，少数派的不同意意见是否必须在草案中高亮展示？

---

### 2.2 草案的"输出时机与内容"

**问题**：
- 草案应该在什么时候生成？
  - Round 3 结束，**无论是否共识**都生成？
  - 还是**仅当共识不足**时才生成？

**当前代码现状**：
- `writePlanningDraft()` 存在但调用点不清晰
- `planning.ai.json` 是最终输出，但无清晰的"这是草案还是规划案"的标记

**草案应该包含哪些内容**：
```
草案结构（Markdown）：
├─ 需求原文
├─ Round 1 & 2 的讨论要点
├─ 各角色的立场摘要
│  ├─ 同意的部分
│  ├─ 有保留意见的部分
│  └─ 直接反对的部分 ⚠️ 重点标记
├─ 小会澄清的内容记录
├─ Round 3 的各角色新结论
├─ 未达成共识的具体问题清单 ⚠️
└─ 后续建议
    ├─ 进行第四轮讨论？
    ├─ 用户补充信息？
    └─ 调整需求范围？
```

**我的问题**：
- 草案应该是"全面的讨论记录"还是"问题聚焦的摘要"？
- 未达成共识的问题应该如何组织和标记，便于用户理解？

---

### 2.3 "使用草案进行 codegen"的风险控制

**问题**：
- 用户强行用草案（未共识）进行 codegen，系统应该如何响应？

**设计选项**：
```
选项 A：强硬阻止
  用户试图用草案 → 系统拒绝 → 必须用规划案

选项 B：警告 + 需要激活码
  用户试图用草案 → 系统警告 ⚠️ 未达成共识的风险
              ↓
           用户需要输入特殊激活码（例如："我理解风险"）
              ↓
           才能继续 codegen

选项 C：双签确认
  用户试图用草案 → 系统显示所有异议
              ↓
           用户需要确认："我已阅读异议，愿意承担后果"
              ↓
           Codegen 时在所有输出文件上标记 "⚠️ Draft-based" 的水位线

选项 D：自动降级
  如果用草案生成代码 → 代码审查阶段自动升级为 "严格审查"（增加检查项）
```

**我的问题**：哪个选项最符合你的风险承受度和用户体验期望？

---

## 三、用户交互与反馈

### 3.1 规划草案提交后的用户选择流程

**问题**：
- 用户看到草案后，有哪些选择？按什么顺序呈现给用户？

**当前文档描述**：
```
用户在收到规划草案后，可以：
1. 上传该草案文件和原始需求，针对此需求开启新的一轮研究
2. 放弃原始需求，针对新需求开始新研究
```

**我的问题**：
- 是否还有其他选择？例如：
  - "基于草案的某个部分建立规划案"（只要 ProductPlanner 和 SystemDesigner 同意就先做？）
  - "回滚到上一版本的规划案重新开始"（如果这不是第一次研究）
  - "邀请人类专家参与讨论"（跳出 AI 讨论，让人类介入）
  - "保存为草案模板，供后续参考"（复用讨论框架）

- "上传该草案文件和原始需求，开启新轮研究" 的具体流程是什么？
  - 用户上传 → 系统自动进入 Round 4？
  - 还是用户上传后需要提供"新的澄清信息"？
  - 系统是否应该"强制显示上次的分歧点"，提示用户"这些问题上次没达成共识"？

---

### 3.2 "规划案"通过后的用户确认

**问题**：
- 规划案（共识达成）生成后，是否还需要用户的"最终确认"才能进入 codegen？

**设计选项**：
```
选项 A：无需确认
  生成规划案 → 自动进入 codegen 阶段

选项 B：展示确认（非强制）
  生成规划案 → 显示"规划已准备好"
             → 用户可查看摘要
             → 用户点击"准备进入开发"或"再看看"

选项 C：强制确认
  生成规划案 → 用户必须确认"我已阅读规划案，同意进入开发"
             → 才能继续

选项 D：二级确认
  生成规划案 → 展示规划案摘要 + 关键风险
             → 用户确认"同意"或"需要调整"
             → 如果"调整"→ 选择调整范围（小修改 vs 重新规划）
```

**我的问题**：
- 用户是否需要有机会在"规划案生成"和"进入 codegen"之间"暂停和反思"？
- 如果需要调整，调整流程是什么？（提交新需求 → 新的完整讨论？还是轻量级补充？）

---

### 3.3 用户体验的"心理承载"

**问题**：
- 三轮讨论 + 小会，整个流程对用户来说会不会太"冗长"和"复杂"？

**当前体验流程**：
```
用户输入需求
  ↓ [提交]
  ↓
等待 Round 1 讨论
  ↓ [显示结果]
  ↓
等待 Round 2 讨论
  ↓ [显示结果]
  ↓
进入小会（用户与 Coach 对话，可能多轮）
  ↓
等待 Round 3 讨论
  ↓ [显示结果]
  ↓
得到草案/规划案
```

**我的问题**：
- 每一步中间应该显示什么信息，让用户了解系统"在做什么"？
- 是否应该提供"中止"或"调整方向"的快捷方式？
- 是否应该有"预计耗时"提示（例如"这个讨论可能需要 2-3 分钟"）？

---

## 四、版本与历史管理

### 4.1 多个规划案的共存

**问题**：
- 假设用户迭代了 5 次，得到了 5 个规划案（来自 5 次不同的需求演化）
- 用户应该能：
  - 查看所有 5 个版本？
  - 在版本之间"对比"？
  - "回滚"到某个版本重新开始？
  - 基于某个版本"fork"一个新分支？

**当前代码现状**：
- `versions.mjs` 按 `v{round}` 快照保存
- 但无"所有版本列表"的查询接口
- 无版本对比功能
- 无版本选择/加载 CLI 命令

**我的问题**：
- 版本管理的力度应该是什么？
  - 轻量级：仅保存版本，用户无法直接操作
  - 中度：提供版本列表和回滚功能
  - 完整：提供版本对比、分支、标签等 Git 风格的管理

---

### 4.2 草案版本与规划案版本的区分

**问题**：
- 系统应该分别追踪"所有中间版本（包括草案）"还是"仅最终规划案"？

**设计选项**：
```
选项 A：仅保存规划案
  只有 planning.ai.json（规划案）进入 versions/ 目录
  草案生成后如果用户不继续迭代，就被丢弃

选项 B：分别保存
  versions/v1_draft/ → 第一个草案
  versions/v1_plan/  → 从草案演化来的规划案
  versions/v2_draft/ → 第二个草案
  ...
  
选项 C：混合保存（推荐）
  versions/v1/ 包含：
    ├─ planning.draft.md      （如果有）
    ├─ planning.ai.json       （规划案）
    ├─ planning.meeting.json  （讨论记录）
    └─ README.md              （版本说明：类型、原因、关键变化）
```

**我的问题**：哪个选项最便于后期追溯和调试？

---

## 五、与后续阶段的协议

### 5.1 Codegen 对规划产物的"严格要求"

**问题**：
- `codegenAgent.mjs` 在启动前应该检查什么？

**当前代码现状**：
- 检查 `state.phase === "plan_review"`
- 读取 `planning.ai.json` 和 `plan-review.json`
- 但无对"这是规划案还是草案"的检查

**应该添加的检查项**：
```
Codegen 前的 Gate：
  ✓ 规划产物是否存在？
  ✓ 是规划案（planning.ai.json）还是草案（planning.draft.md）？
    ├─ 如果是草案 → 警告 + 风险确认
    └─ 如果是规划案 → 继续
  ✓ plan-review.json 是否通过？
  ✓ test_plan 是否完整（有 cases）？
  ✓ requirements 是否非空？
  ✓ acceptance criteria 是否明确？
```

**我的问题**：
- 如果某些必要字段缺失，codegen 应该"拒绝启动"还是"生成代码但标记为风险"？
- Test Plan 是否是"必须项"还是"可选项"？

---

### 5.2 规划案中的哪些字段会直接影响代码生成？

**问题**：
- `planning.ai.json` 有很多字段（why, what, requirements, draft_files, acceptance, scope, non_goals, open_questions, test_plan）
- Codegen 会用到哪些？每个字段的重要性排序是什么？

**当前代码现状**：
- 看起来主要用 `requirements` 和 `draft_files`
- `test_plan` 的使用方式不清晰
- `non_goals` 和 `open_questions` 是否有用？

**我的问题**：
- 能否列一个"字段重要性排序"？
- 如果某个字段为空或缺失，codegen 应该如何处理？
- "open_questions"（未达成共识的问题）应该被标记在代码中吗？

---

### 5.3 Code Review 中是否应该"回溯规划讨论"

**问题**：
- Code Review Agent 在审查代码时，是否应该有权访问规划阶段的讨论记录（包括各角色的立场、异议、澄清过程）？

**设计选项**：
```
选项 A：无访问权限
  Code Review 仅基于最终规划案审查代码
  
选项 B：只读访问规划案
  Code Review 可访问 planning.ai.json 和 planning.meeting.json
  但不涉及草稿或讨论细节
  
选项 C：完整访问
  Code Review 可访问所有规划产物，包括讨论记录
  如果代码与某个角色的疑虑不符，可在 review 中标记
```

**我的问题**：
- Code Review 是否应该了解"规划中哪些地方还有疑虑"？
- 这是否会帮助 Code Review 更细致地审查相关部分？

---

## 六、系统级优化

### 6.1 规划阶段的"中止与恢复"

**问题**：
- 用户在 Round 1、Round 2、小会、Round 3 的任何阶段都可能想"中止"
- 系统应该如何处理？

**设计选项**：
```
选项 A：无法中止
  一旦启动就必须完成

选项 B：支持中止但丢弃
  用户可以 Ctrl+C 中止 → 本轮讨论丢弃 → 下次从头开始

选项 C：支持中止并保存
  用户可以中止 → 系统保存"中间状态"
              → 下次可以继续从上次中止的地方恢复
              （例如：中止在小会中间 → 下次恢复时直接进入小会继续）

选项 D：支持"降级"而非中止
  用户在 Round 3 中止 → 系统根据已有信息生成"不完整的草案"
                     → 用户可以基于这个不完整草案继续迭代
```

**我的问题**：哪个选项最务实？

---

### 6.2 AI 模型失败或超时时的处理

**问题**：
- 假设 Round 2 中某个 AI 调用超时或返回错误
- 系统应该如何处理？

**设计选项**：
```
选项 A：整个讨论失败
  某个角色失败 → 整个讨论放弃 → 用户需要重新开始

选项 B：跳过失败的角色
  某个角色失败 → 这个角色缺席 Round 2
              → 继续其他角色的讨论
              → 最后在"异议"中标记"某角色未能参与"

选项 C：自动重试
  某个角色失败 → 自动重试 3 次
              → 如果仍然失败 → 跳过该角色

选项 D：用户干预
  某个角色失败 → 询问用户：
              ├─ 自动使用该角色的上一版本结论？
              ├─ 跳过该角色？
              └─ 重试？
```

**我的问题**：生产环境中应该用哪个策略？

---

### 6.3 规划阶段的"可观测性"与日志

**问题**：
- 用户应该能看到什么信息，便于理解系统"在做什么"、"为什么这样做"？

**当前代码现状**：
- `logs` 记录系统操作，但展示的详细度不清晰
- `planning.meeting.json` 记录了讨论，但普通用户可能看不懂 JSON

**应该改进的地方**：
```
用户可见的日志应该包括：
  ✓ "正在 Round 1 讨论..."
  ✓ "收到 ProductPlanner 的结论：同意"
  ✓ "收到 SystemDesigner 的结论：有保留意见 - 设计复杂度高"
  ✓ "Round 2 启动..."
  ✓ "检测到 3 个需要澄清的问题"
  ✓ "进入澄清小会..."
  ✓ "用户回答了问题，纳入讨论..."
  ✓ "Round 3 启动..."
  ✓ "所有角色都同意 → 生成规划案"
  或
  ✓ "TestPlanner 仍有异议 → 生成规划草案"
```

**我的问题**：
- 这个信息粒度够吗？还是应该更详细或更简洁？
- 是否应该为"草案"和"规划案"添加不同的视觉标记（颜色、图标）？

---

## 七、未来扩展

### 7.1 "人类专家介入"的设计空间

**问题**：
- 当 AI 讨论陷入僵局（多轮后仍未共识）时，是否应该允许人类（例如技术leader）介入？

**设计方向**（可选）：
```
未来可能的扩展：
  - "邀请人类审阅"：暂停讨论，人类看到当前状态和分歧，给出建议
  - "人类打破平局"：多个角色意见相悖时，人类决策
  - "人类标注训练数据"：保存讨论记录，用于改进 AI 角色的 prompt
```

**我的问题**：这是否在你的视野内？还是先聚焦纯 AI 讨论？

---

### 7.2 "规划案质量评分"

**问题**：
- 规划案生成后，系统是否应该给出一个"质量评分"（例如 0-100%），反映"这个规划的清晰度、完整性、可靠性"？

**可能的评分维度**：
```
规划案质量评分：
  - 清晰度（需求描述是否明确？） → 20%
  - 完整性（所有关键字段是否填充？） → 20%
  - 风险意识（open_questions、non_goals 是否完整？） → 20%
  - 共识强度（所有角色是否都同意？） → 20%
  - 稳定性（讨论是否收敛，或仍在波动？） → 20%
  ─────────────────────
  总分 = 各维度平均值
```

**我的问题**：这对用户决策有帮助吗？还是会增加复杂性？

---

## 八、总结与优先级

### 高优先级（必须在 M11-3 前完成）
1. **两轮讨论的快速路径**：所有角色同意时，是否跳过 Round 2 和小会？
2. **草案 vs 规划案的输出标准**：共识的量化门槛是什么？
3. **使用草案的风险控制**：如何防止用户误用未共识的草案进行 codegen？
4. **用户选择流程**：看到草案后用户有什么明确的选择？

### 中优先级（M12 中完成）
5. **多轮澄清的流程设计**：串联还是并联？每个问题后是否确认？
6. **Round 3 的"重新发言"策略**：全员重新还是分层重新？
7. **版本管理的力度**：版本对比、回滚等功能的完整性
8. **用户体验的简化**：如何让三轮讨论+小会不显得冗长？

### 低优先级（未来优化）
9. 人类专家介入机制
10. 规划案质量评分
11. 规划→任务映射的可视化

---

**等待你的反馈**：上面这 19 个具体设计问题中，哪些最需要立即决策？哪些可以先留待讨论？

